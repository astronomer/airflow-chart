# Default values for airflow.
# This is a YAML-formatted file.
# Declare variables to be passed into your templates.

airflow:
  # group of airflow user
  gid: 50000

  # Airflow home directory; Used for mount paths
  airflowHome: "/usr/local/airflow"

  # Airflow executor
  # Options: SequentialExecutor, LocalExecutor, CeleryExecutor, KubernetesExecutor
  executor: "KubernetesExecutor"

  # Airflow version
  airflowVersion: 2.0.0

  # Default airflow repository
  defaultAirflowRepository: quay.io/astronomer/ap-airflow

  # Default airflow tag to deploy
  defaultAirflowTag: 2.0.0-buster

  # Astronomer Airflow images
  images:
    airflow:
    statsd:
      repository: quay.io/astronomer/ap-statsd-exporter
      tag: 0.18.0
    redis:
      repository: quay.io/astronomer/ap-redis
      tag: 6.2.1
    pgbouncer:
      repository: quay.io/astronomer/ap-pgbouncer
      tag: 1.16.0
    pgbouncerExporter:
      repository: quay.io/astronomer/ap-pgbouncer-exporter
      tag: 0.9.2

  # Airflow scheduler settings
  scheduler:
    livenessProbe:
      timeoutSeconds: 30
    strategy:
      type: Recreate
    affinity:
      podAntiAffinity:
        preferredDuringSchedulingIgnoredDuringExecution:
          - weight: 100
            podAffinityTerm:
              labelSelector:
                matchExpressions:
                  - key: component
                    operator: In
                    values:
                      - scheduler
              topologyKey: "kubernetes.io/hostname"
    logGroomerSidecar:
      args: ["/usr/local/bin/clean-airflow-logs"]

  # Airflow webserver settings
  webserver:
    allowPodLogReading: false
    args: ["airflow", "webserver"]
    webserverConfig: |
      import os
      from airflow import configuration as conf
      from flask_appbuilder.security.manager import AUTH_REMOTE_USER
      basedir = os.path.abspath(os.path.dirname(__file__))

      # The SQLAlchemy connection string.
      SQLALCHEMY_DATABASE_URI = conf.get('core', 'SQL_ALCHEMY_CONN')

      # Flask-WTF flag for CSRF
      CSRF_ENABLED = True

      # ----------------------------------------------------
      # AUTHENTICATION CONFIG
      # ----------------------------------------------------
      {{- if .Values.useAstroSecurityManager }}
      AUTH_TYPE = AUTH_REMOTE_USER

      from astronomer.flask_appbuilder.security import AirflowAstroSecurityManager
      SECURITY_MANAGER_CLASS = AirflowAstroSecurityManager
      {{- end }}

  # Airflow worker settings
  workers:
    persistence:
      # Enable persistent volumes
      enabled: false
    logGroomerSidecar:
      args: ["/usr/local/bin/clean-airflow-logs"]

  # Pgbouncer settings
  pgbouncer:
    # Pool sizes
    metadataPoolSize: 3
    resultBackendPoolSize: 2

  # Elasticsearch logging configuration
  elasticsearch:
    connection:
      scheme: http

  cleanup:
    command: ["airflow-cleanup-pods", "--namespace={{ .Release.Namespace }}"]
    args: ~

  airflowLocalSettings: |
    {{- if semverCompare "<1.10.12" .Values.airflowVersion }}

    from airflow.contrib.kubernetes.pod import Pod
    from airflow.configuration import conf

    def pod_mutation_hook(pod: Pod):

        extra_labels = {
            "kubernetes_executor": "False",
            "kubernetes_pod_operator": "False"
        }

        if 'airflow-worker' in pod.labels.keys() or \
                conf.get('core', 'EXECUTOR') == "KubernetesExecutor":
            extra_labels["kubernetes_executor"] = "True"
        else:
            extra_labels["kubernetes_pod_operator"] = "True"

        pod.labels.update(extra_labels)
        pod.tolerations += {{ toJson .Values.podMutation.tolerations }}
        pod.affinity.update({{ toJson .Values.podMutation.affinity }})
    {{- else }}
    from kubernetes.client import models as k8s
    from airflow.configuration import conf

    def pod_mutation_hook(pod: k8s.V1Pod):

        extra_labels = {
            "kubernetes_executor": "False",
            "kubernetes_pod_operator": "False"
        }

        if 'airflow-worker' in pod.metadata.labels.keys() or \
                conf.get('core', 'EXECUTOR') == "KubernetesExecutor":
            extra_labels["kubernetes_executor"] = "True"
        else:
            extra_labels["kubernetes_pod_operator"] = "True"

        pod.metadata.labels.update(extra_labels)
        if pod.spec.tolerations:
            pod.spec.tolerations += {{ toJson .Values.podMutation.tolerations }}
        else:
            pod.spec.tolerations = {{ toJson .Values.podMutation.tolerations }}

        if pod.spec.affinity:
            pod.spec.affinity = pod.spec.affinity.to_dict().update({{ toJson .Values.podMutation.affinity }})
        else:
            pod.spec.affinity = {{ toJson .Values.podMutation.affinity }}

    {{- end }}

  # Config Settings for pod_mutation_hook
  podMutation:
    # Tolerations provided here would be applied using pod_mutation_hook
    # So any pods spun up using KubernetesExecutor or KubernetesPodOperator will contain these tolerations.
    tolerations: []
    #  - key: "dynamic-pods"
    #    operator: "Equal"
    #    value: "true"
    #    effect: "NoSchedule"

    # Pods spun up would land in the node that matches the affinity
    affinity: {}
    #  nodeAffinity:
    #    requiredDuringSchedulingIgnoredDuringExecution:
    #      nodeSelectorTerms:
    #        - matchExpressions:
    #            - key: "astronomer.io/dynamic-pods"
    #              operator: In
    #              values:
    #                - "true"

  migrateDatabaseJob:
    annotations:
      "sidecar.istio.io/inject": "false"

  config:
    api:
      auth_backend: '{{ ternary "astronomer.flask_appbuilder.current_user_backend" "airflow.api.auth.backend.deny_all" .Values.useAstroSecurityManager }}'
    operators:
      default_queue: celery
    celery: # compat
      default_queue: celery
    webserver:
      expose_config: True
    elasticsearch:
      write_stdout: True
      elasticsearch_write_stdout: True
      elasticsearch_json_format: True
      elasticsearch_log_id_template: "{dag_id}_{task_id}_{execution_date}_{try_number}"
    kubernetes:
      dags_in_image: True
    # Only required when running on the platform, but works elsewhere too
    astronomer:
      jwt_signing_cert: /etc/airflow/tls/tls.crt

  # Should the Astronomer Security Manager be used for the webserver
  useAstroSecurityManager: False

# Airflow Worker Config
# TODO: should this be under airflow.workers just for consistency?
# TODO: does the platform actually enable this in some cases?
workers:
  # Apply a HorizontalPodAutoscaler
  autoscaling:
    enabled: false
    minReplicas: 1
    maxReplicas: 10
    targetCPUUtilization: 80
    targetMemoryUtilization: 80

# Enable security context constraints required for OpenShift
sccEnabled: false

# Extra objects to deploy (these are passed through `tpl`)
extraObjects: []

# Enable nginx auth sidecar
authSidecar:
  enabled: false
  repository: nginxinc/nginx-unprivileged
  tag: stable
  pullPolicy: IfNotPresent
  port: 8084

# Ingress configuration
ingress:
  # Enable ingress resource
  enabled: false

  # Enable for cert-manager or kube-lego
  acme: false

  # Name of tls secret to use on ingress
  tlsSecretName: ~

  # Annotations always injected when configuring webserver Ingress object
  webserverAnnotations: {}

  # Annotations always injected when configuring Flower Ingress object
  flowerAnnotations: {}

  # Base domain for ingress vhosts
  baseDomain: ~

  # Enable platform authentication
  auth:
    enabled: true

#####################################
# Leftovers

# Pgbouncer settings
#pgbouncer:
#  networkPolicies:
#    enabled: true
#    # TODO: Originated from https://github.com/astronomer/issues/issues/2516

platform:
  release: ~
